{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention_RNN.py          offline-test.pkl\r\n",
      "data_iterator.py          offline-train.pkl\r\n",
      "densenet121-a639ec97.pth  \u001b[0m\u001b[01;34moff_printed_image_train\u001b[0m/\r\n",
      "Densenet_testway.py       \u001b[01;34m__pycache__\u001b[0m/\r\n",
      "Densenet_torchvision.py   README.md\r\n",
      "dictionary.txt            test_caption.txt\r\n",
      "gen_pkl.py                test_right_SGD_bs8_te1_mask_conv_bn_b_dr05.txt\r\n",
      "\u001b[01;34mHMER_v2.0\u001b[0m/                train_caption.txt\r\n",
      "LICENSE                   \u001b[01;34mtraining_data\u001b[0m/\r\n",
      "\u001b[01;34mmodel\u001b[0m/                    train.ipynb\r\n",
      "\u001b[01;34moff_image_test\u001b[0m/           Train.py\r\n",
      "\u001b[01;34moff_image_train\u001b[0m/          version_before.md\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy\n",
    "import torch.utils.data as data\n",
    "from data_iterator import dataIterator\n",
    "from Densenet_torchvision import densenet121\n",
    "from Attention_RNN import AttnDecoderRNN\n",
    "#from Resnet101 import resnet101\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(dictFile):\n",
    "    fp=open(dictFile)\n",
    "    stuff=fp.readlines()\n",
    "    fp.close()\n",
    "    lexicon={}\n",
    "    for l in stuff:\n",
    "        w=l.strip().split()\n",
    "        lexicon[w[0]]=int(w[1])\n",
    "    print('total words/phones',len(lexicon))\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=['./offline-train.pkl','./train_caption.txt']\n",
    "valid_datasets=['./offline-test.pkl', './test_caption.txt']\n",
    "dictionaries=['./dictionary.txt']\n",
    "batch_Imagesize=500000\n",
    "valid_batch_Imagesize=500000\n",
    "# batch_size for training and testing\n",
    "batch_size=6\n",
    "batch_size_t=6\n",
    "# the max (label length/Image size) in training and testing\n",
    "# you can change 'maxlen','maxImagesize' by the size of your GPU\n",
    "maxlen=48\n",
    "maxImagesize= 100000\n",
    "# hidden_size in RNN\n",
    "hidden_size = 256\n",
    "# teacher_forcing_ratio \n",
    "teacher_forcing_ratio = 1\n",
    "# change the gpu id \n",
    "gpu = [0]\n",
    "# learning rate\n",
    "lr_rate = 0.0001\n",
    "# flag to remember when to change the learning rate\n",
    "flag = 0\n",
    "# exprate\n",
    "exprate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words/phones 112\n"
     ]
    }
   ],
   "source": [
    "worddicts = load_dict(dictionaries[0])\n",
    "worddicts_r = [None] * len(worddicts)\n",
    "for kk, vv in worddicts.items():\n",
    "        worddicts_r[vv] = kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total  8359 batch data loaded\n",
      "ignore 476 images\n",
      "total  8359 batch data loaded\n",
      "ignore 476 images\n",
      "total  925 batch data loaded\n",
      "ignore 61 images\n"
     ]
    }
   ],
   "source": [
    "train,train_label = dataIterator(\n",
    "                                    datasets[0], datasets[1],worddicts,batch_size=1,\n",
    "                                    batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize\n",
    "                                 )\n",
    "len_train = len(train)\n",
    "\n",
    "printed, printed_label = dataIterator(\n",
    "                                    datasets[0],datasets[1],worddicts,batch_size=1,\n",
    "                                    batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize\n",
    "                                )\n",
    "\n",
    "test,test_label = dataIterator(\n",
    "                                    valid_datasets[0],valid_datasets[1],worddicts,batch_size=1,\n",
    "                                    batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize\n",
    "                                )\n",
    "len_test = len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_dset(data.Dataset):\n",
    "    def __init__(self,train,train_label,batch_size):\n",
    "        self.train = train\n",
    "        self.train_label = train_label\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        train_setting = torch.from_numpy(numpy.array(self.train[index]))\n",
    "        label_setting = torch.from_numpy(numpy.array(self.train_label[index])).type(torch.LongTensor)\n",
    "\n",
    "        size = train_setting.size()\n",
    "        train_setting = train_setting.view(1,size[2],size[3])\n",
    "        label_setting = label_setting.view(-1)\n",
    "        return train_setting,label_setting\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train)\n",
    "\n",
    "off_image_train = custom_dset(train,train_label,batch_size)\n",
    "off_image_printed = custom_dset(printed,printed_label,batch_size)\n",
    "off_image_test = custom_dset(test,test_label,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch.sort(key=lambda x: len(x[1]), reverse=True)\n",
    "    img, label = zip(*batch)\n",
    "    aa1 = 0\n",
    "    bb1 = 0\n",
    "    k = 0\n",
    "    k1 = 0\n",
    "    max_len = len(label[0])+1\n",
    "    for j in range(len(img)):\n",
    "        size = img[j].size()\n",
    "        if size[1] > aa1:\n",
    "            aa1 = size[1]\n",
    "        if size[2] > bb1:\n",
    "            bb1 = size[2]\n",
    "\n",
    "    for ii in img:\n",
    "        ii = ii.float()\n",
    "        img_size_h = ii.size()[1]\n",
    "        img_size_w = ii.size()[2]\n",
    "        img_mask_sub_s = torch.ones(1,img_size_h,img_size_w).type(torch.FloatTensor)\n",
    "        img_mask_sub_s = img_mask_sub_s*255.0\n",
    "        img_mask_sub = torch.cat((ii,img_mask_sub_s),dim=0)\n",
    "        padding_h = aa1-img_size_h\n",
    "        padding_w = bb1-img_size_w\n",
    "        m = torch.nn.ZeroPad2d((0,padding_w,0,padding_h))\n",
    "        img_mask_sub_padding = m(img_mask_sub)\n",
    "        img_mask_sub_padding = img_mask_sub_padding.unsqueeze(0)\n",
    "        if k==0:\n",
    "            img_padding_mask = img_mask_sub_padding\n",
    "        else:\n",
    "            img_padding_mask = torch.cat((img_padding_mask,img_mask_sub_padding),dim=0)\n",
    "        k = k+1\n",
    "\n",
    "    for ii1 in label:\n",
    "        ii1 = ii1.long()\n",
    "        ii1 = ii1.unsqueeze(0)\n",
    "        ii1_len = ii1.size()[1]\n",
    "        m = torch.nn.ZeroPad2d((0,max_len-ii1_len,0,0))\n",
    "        ii1_padding = m(ii1)\n",
    "        if k1 == 0:\n",
    "            label_padding = ii1_padding\n",
    "        else:\n",
    "            label_padding = torch.cat((label_padding,ii1_padding),dim=0)\n",
    "        k1 = k1+1\n",
    "\n",
    "    img_padding_mask = img_padding_mask/255.0\n",
    "    return img_padding_mask, label_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       " tensor([ 94,  47,  57,  65,  52, 110,  93,  83,  57,  65,  73,  94,  47,  57,\n",
       "          52, 110, 110,  57,  65,  73,  34,   2,  57,  68,  73,  75,  57,  65,\n",
       "         110,  34,  94,  75,  57,  65, 110,  47,  57,  52, 110, 110, 110]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = off_image_train,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    collate_fn = collate_fn,\n",
    "    num_workers=2,\n",
    "    )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = off_image_test,\n",
    "    batch_size = batch_size_t,\n",
    "    shuffle = True,\n",
    "    collate_fn = collate_fn,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "printed_loader = torch.utils.data.DataLoader(\n",
    "    dataset = off_image_printed,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    collate_fn = collate_fn,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(target_length,attn_decoder1,\n",
    "             output_highfeature, output_area,y,criterion,encoder_optimizer1,decoder_optimizer1,x_mean,dense_input,h_mask,w_mask,gpu,\n",
    "             decoder_input,decoder_hidden,attention_sum,decoder_attention):\n",
    "    loss = 0\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    flag_z = [0]*batch_size\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        encoder_optimizer1.zero_grad()\n",
    "        decoder_optimizer1.zero_grad()\n",
    "        my_num = 0\n",
    "\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention, attention_sum = attn_decoder1(decoder_input,\n",
    "                                                                                             decoder_hidden,\n",
    "                                                                                             output_highfeature,\n",
    "                                                                                             output_area,\n",
    "                                                                                             attention_sum,\n",
    "                                                                                             decoder_attention,\n",
    "                                                                                             dense_input,batch_size,h_mask,w_mask,gpu)\n",
    "            \n",
    "#             decoder_output_p, decoder_hidden_p, decoder_attention_p, attention_sum_p = attn_decoder1(decoder_input,\n",
    "#                                                                                              decoder_hidden,\n",
    "#                                                                                              output_highfeature,\n",
    "#                                                                                              output_area,\n",
    "#                                                                                              attention_sum,\n",
    "#                                                                                              decoder_attention,\n",
    "#                                                                                              dense_input,batch_size,h_mask,w_mask,gpu)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(decoder_output.size()) #(batch,1,112)\n",
    "            y = y.unsqueeze(0)\n",
    "            for i in range(batch_size):\n",
    "                if int(y[0][i][di]) == 0:\n",
    "                    flag_z[i] = flag_z[i]+1\n",
    "                    if flag_z[i] > 1:\n",
    "                        continue\n",
    "                    else:\n",
    "                        loss += criterion(decoder_output[i], y[:,i,di])\n",
    "                        \n",
    "                else:\n",
    "                    loss += criterion(decoder_output[i], y[:,i,di])\n",
    "\n",
    "            if int(y[0][0][di]) == 0:\n",
    "                break\n",
    "            decoder_input = y[:,:,di]\n",
    "            decoder_input = decoder_input.squeeze(0)\n",
    "            y = y.squeeze(0)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer1.step()\n",
    "        decoder_optimizer1.step()\n",
    "        return loss.item()\n",
    "\n",
    "    else:\n",
    "        encoder_optimizer1.zero_grad()\n",
    "        decoder_optimizer1.zero_grad()\n",
    "        my_num = 0\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention,attention_sum= attn_decoder1(decoder_input, decoder_hidden,\n",
    "                                                                                output_highfeature, output_area,\n",
    "                                                                                attention_sum,decoder_attention,dense_input,batch_size,\n",
    "                                                                                h_mask,w_mask,gpu)\n",
    "            print(decoder_output.size()) #1*10*112\n",
    "            print(y.size())  #1*37\n",
    "            #topi (b,1)\n",
    "            topv,topi = torch.max(decoder_output,2)\n",
    "            decoder_input = topi\n",
    "            decoder_input = decoder_input.view(batch_size)\n",
    "\n",
    "            y = y.unsqueeze(0)\n",
    "            #print(y_t)\n",
    "\n",
    "            # 1*bs*17\n",
    "            for k in range(batch_size):\n",
    "                if int(y[0][k][di]) == 0:\n",
    "                    flag_z[k] = flag_z[k]+1\n",
    "                    if flag_z[k] > 1:\n",
    "                        continue\n",
    "                    else:\n",
    "                        loss += criterion(decoder_output[k], y[:,k,di])\n",
    "                        loss2 += criterion(decoder_output_p[i], y[:,i,di])\n",
    "                        loss_mse1 = nn.MSELoss(decoder_output[i], decoder_output_p[i])\n",
    "                else:\n",
    "                    loss += criterion(decoder_output[k], y[:,k,di])\n",
    "\n",
    "            y = y.squeeze(0)\n",
    "            # if int(topi[0]) == 0:\n",
    "            #     break\n",
    "        loss.backward()\n",
    "        encoder_optimizer1.step()\n",
    "        decoder_optimizer1.step()\n",
    "        return loss.item()\n",
    "\n",
    "def imresize(im,sz):\n",
    "    pil_im = Image.fromarray(im)\n",
    "    return numpy.array(pil_im.resize(sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0501, -0.0113,  0.0032,  ..., -0.0574, -0.0160, -0.0085]],\n",
       "\n",
       "        [[ 0.0170, -0.0278,  0.0086,  ..., -0.0131,  0.0538, -0.0161]],\n",
       "\n",
       "        [[-0.0166,  0.0507, -0.0457,  ..., -0.0370, -0.0382, -0.0227]],\n",
       "\n",
       "        [[-0.0260,  0.0573, -0.0011,  ..., -0.0460, -0.0461,  0.0228]],\n",
       "\n",
       "        [[-0.0549, -0.0043,  0.0343,  ..., -0.0127,  0.0318,  0.0313]],\n",
       "\n",
       "        [[ 0.0256,  0.0074, -0.0416,  ...,  0.0428, -0.0072,  0.0333]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = densenet121()\n",
    "\n",
    "pthfile = r'densenet121-a639ec97.pth'\n",
    "pretrained_dict = torch.load(pthfile) \n",
    "encoder_dict = encoder.state_dict()\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in encoder_dict}\n",
    "encoder_dict.update(pretrained_dict)\n",
    "encoder.load_state_dict(encoder_dict)\n",
    "\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size,112,dropout_p=0.5)\n",
    "\n",
    "encoder=encoder.cuda()\n",
    "attn_decoder1 = attn_decoder1.cuda()\n",
    "encoder = torch.nn.DataParallel(encoder, device_ids=gpu)\n",
    "attn_decoder1 = torch.nn.DataParallel(attn_decoder1, device_ids=gpu)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "# encoder.load_state_dict(torch.load('model/encoder_lr0.00001_BN_te1_d05_SGD_bs8_mask_conv_bn_b.pkl'))\n",
    "# attn_decoder1.load_state_dict(torch.load('model/attn_decoder_lr0.00001_BN_te1_d05_SGD_bs8_mask_conv_bn_b.pkl'))\n",
    "decoder_input_init = torch.LongTensor([111]*batch_size).cuda()\n",
    "decoder_hidden_init = torch.randn(batch_size, 1, hidden_size).cuda()\n",
    "nn.init.xavier_uniform_(decoder_hidden_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n",
      "torch.Size([6, 1, 112])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 12.88 MiB (GPU 0; 10.92 GiB total capacity; 2.76 GiB already allocated; 9.06 MiB free; 79.95 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-16bd6455c164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m         running_loss += my_train(target_length,attn_decoder1,output_highfeature,\n\u001b[1;32m     63\u001b[0m                                 \u001b[0moutput_area\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_optimizer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_optimizer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdense_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                                 decoder_input_init,decoder_hidden_init,attention_sum_init,decoder_attention_init)\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-263f24c4717f>\u001b[0m in \u001b[0;36mmy_train\u001b[0;34m(target_length, attn_decoder1, output_highfeature, output_area, y, criterion, encoder_optimizer1, decoder_optimizer1, x_mean, dense_input, h_mask, w_mask, gpu, decoder_input, decoder_hidden, attention_sum, decoder_attention)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                                                              \u001b[0mattention_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                                                                              \u001b[0mdecoder_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                                                                              dense_input,batch_size,h_mask,w_mask,gpu)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#             decoder_output_p, decoder_hidden_p, decoder_attention_p, attention_sum_p = attn_decoder1(decoder_input,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hieutb/hmer/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hieutb/hmer/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hieutb/hmer/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hieutb/baohg/HMER/Attention_RNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_a, hidden, encoder_outputs, bb, attention_sum, decoder_attention, dense_input, batch_size, h_mask, w_mask, gpu)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# ct is context vector (batch,128)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0met_div_all\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 12.88 MiB (GPU 0; 10.92 GiB total capacity; 2.76 GiB already allocated; 9.06 MiB free; 79.95 MiB cached)"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
    "    decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
    "\n",
    "    # # if using SGD optimizer\n",
    "    # if epoch+1 == 50:\n",
    "    #     lr_rate = lr_rate/10\n",
    "    #     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
    "    #     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
    "    # if epoch+1 == 75:\n",
    "    #     lr_rate = lr_rate/10\n",
    "    #     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
    "    #     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
    "\n",
    "\n",
    "    running_loss=0\n",
    "    whole_loss = 0\n",
    "\n",
    "    encoder.train(mode=True)\n",
    "    attn_decoder1.train(mode=True)\n",
    "\n",
    "    # this is the train\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        if x.size()[0]<batch_size:\n",
    "            break\n",
    "        h_mask = []\n",
    "        w_mask = []\n",
    "        for i in x:\n",
    "            #h*w\n",
    "            size_mask = i[1].size()\n",
    "            s_w = str(i[1][0])\n",
    "            s_h = str(i[1][:,1])\n",
    "            w = s_w.count('1')\n",
    "            h = s_h.count('1')\n",
    "            h_comp = int(h/16)+1\n",
    "            w_comp = int(w/16)+1\n",
    "            h_mask.append(h_comp)\n",
    "            w_mask.append(w_comp)\n",
    "\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        # out is CNN featuremaps\n",
    "        output_highfeature = encoder(x)\n",
    "        x_mean=[]\n",
    "        for i in output_highfeature:\n",
    "            x_mean.append(float(torch.mean(i)))\n",
    "        # x_mean = torch.mean(output_highfeature)\n",
    "        # x_mean = float(x_mean)\n",
    "        for i in range(batch_size):\n",
    "            decoder_hidden_init[i] = decoder_hidden_init[i]*x_mean[i]\n",
    "            decoder_hidden_init[i] = torch.tanh(decoder_hidden_init[i])\n",
    "\n",
    "        # dense_input is height and output_area is width which is bb\n",
    "        output_area1 = output_highfeature.size()\n",
    "\n",
    "        output_area = output_area1[3]\n",
    "        dense_input = output_area1[2]\n",
    "        target_length = y.size()[1]\n",
    "        attention_sum_init = torch.zeros(batch_size,1,dense_input,output_area).cuda()\n",
    "        decoder_attention_init = torch.zeros(batch_size,1,dense_input,output_area).cuda()\n",
    "\n",
    "        running_loss += my_train(target_length,attn_decoder1,output_highfeature,\n",
    "                                output_area,y,criterion,encoder_optimizer1,decoder_optimizer1,x_mean,dense_input,h_mask,w_mask,gpu,\n",
    "                                decoder_input_init,decoder_hidden_init,attention_sum_init,decoder_attention_init)\n",
    "\n",
    "        \n",
    "        if step % 20 == 19:\n",
    "            pre = ((step+1)/len_train)*100*batch_size\n",
    "            whole_loss += running_loss\n",
    "            running_loss = running_loss/(batch_size*20)\n",
    "            print('epoch is %d, lr rate is %.5f, te is %.3f, batch_size is %d, loading for %.3f%%, running_loss is %f' %(epoch,lr_rate,teacher_forcing_ratio, batch_size,pre,running_loss))\n",
    "            # with open(\"training_data/running_loss_%.5f_pre_GN_te05_d02_all.txt\" %(lr_rate),\"a\") as f:\n",
    "            #     f.write(\"%s\\n\"%(str(running_loss)))\n",
    "            running_loss = 0\n",
    "\n",
    "    loss_all_out = whole_loss / len_train\n",
    "    print(\"epoch is %d, the whole loss is %f\" % (epoch, loss_all_out))\n",
    "    # with open(\"training_data/whole_loss_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
    "    #     f.write(\"%s\\n\" % (str(loss_all_out)))\n",
    "\n",
    "    # this is the prediction and compute wer loss\n",
    "    total_dist = 0\n",
    "    total_label = 0\n",
    "    total_line = 0\n",
    "    total_line_rec = 0\n",
    "    whole_loss_t = 0\n",
    "\n",
    "    encoder.eval()\n",
    "    attn_decoder1.eval()\n",
    "    print('Now, begin testing!!')\n",
    "\n",
    "    for step_t, (x_t, y_t) in enumerate(test_loader):\n",
    "        x_real_high = x_t.size()[2]\n",
    "        x_real_width = x_t.size()[3]\n",
    "        if x_t.size()[0]<batch_size_t:\n",
    "            break\n",
    "        print('testing for %.3f%%'%(step_t*100*batch_size_t/len_test),end='\\r')\n",
    "        h_mask_t = []\n",
    "        w_mask_t = []\n",
    "        for i in x_t:\n",
    "            #h*w\n",
    "            size_mask_t = i[1].size()\n",
    "            s_w_t = str(i[1][0])\n",
    "            s_h_t = str(i[1][:,1])\n",
    "            w_t = s_w_t.count('1')\n",
    "            h_t = s_h_t.count('1')\n",
    "            h_comp_t = int(h_t/16)+1\n",
    "            w_comp_t = int(w_t/16)+1\n",
    "            h_mask_t.append(h_comp_t)\n",
    "            w_mask_t.append(w_comp_t)\n",
    "\n",
    "        x_t = x_t.cuda()\n",
    "        y_t = y_t.cuda()\n",
    "        output_highfeature_t = encoder(x_t)\n",
    "\n",
    "        x_mean_t = torch.mean(output_highfeature_t)\n",
    "        x_mean_t = float(x_mean_t)\n",
    "        output_area_t1 = output_highfeature_t.size()\n",
    "        output_area_t = output_area_t1[3]\n",
    "        dense_input = output_area_t1[2]\n",
    "\n",
    "        decoder_input_t = torch.LongTensor([111]*batch_size_t)\n",
    "        decoder_input_t = decoder_input_t.cuda()\n",
    "        decoder_hidden_t = torch.randn(batch_size_t, 1, hidden_size).cuda()\n",
    "        nn.init.xavier_uniform_(decoder_hidden_t)\n",
    "\n",
    "        x_mean_t=[]\n",
    "        for i in output_highfeature_t:\n",
    "            x_mean_t.append(float(torch.mean(i)))\n",
    "        # x_mean = torch.mean(output_highfeature)\n",
    "        # x_mean = float(x_mean)\n",
    "        for i in range(batch_size_t):\n",
    "            decoder_hidden_t[i] = decoder_hidden_t[i]*x_mean_t[i]\n",
    "            decoder_hidden_t[i] = torch.tanh(decoder_hidden_t[i])\n",
    "\n",
    "        prediction = torch.zeros(batch_size_t,maxlen)\n",
    "        #label = torch.zeros(batch_size_t,maxlen)\n",
    "        prediction_sub = []\n",
    "        label_sub = []\n",
    "        decoder_attention_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
    "        attention_sum_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
    "        flag_z_t = [0]*batch_size_t\n",
    "        loss_t = 0\n",
    "        m = torch.nn.ZeroPad2d((0,maxlen-y_t.size()[1],0,0))\n",
    "        y_t = m(y_t)\n",
    "        for i in range(maxlen):\n",
    "            decoder_output, decoder_hidden_t, decoder_attention_t, attention_sum_t = attn_decoder1(decoder_input_t,\n",
    "                                                                                             decoder_hidden_t,\n",
    "                                                                                             output_highfeature_t,\n",
    "                                                                                             output_area_t,\n",
    "                                                                                             attention_sum_t,\n",
    "                                                                                             decoder_attention_t,dense_input,batch_size_t,h_mask_t,w_mask_t,gpu)\n",
    "\n",
    "            ### you can see the attention when testing\n",
    "\n",
    "            # print('this is',i)\n",
    "            # for i in range(batch_size_t):\n",
    "            #     x_real = numpy.array(x_t[i][0].data.cpu())\n",
    "\n",
    "            #     show = numpy.array(decoder_attention_t[i][0].data.cpu())\n",
    "            #     show = imresize(show,(x_real_width,x_real_high))\n",
    "            #     k_max = show.max()\n",
    "            #     show = show/k_max\n",
    "\n",
    "            #     show_x = x_real+show\n",
    "            #     plt.imshow(show_x, interpolation='nearest', cmap='gray_r')\n",
    "            #     plt.show()\n",
    "            \n",
    "            topv,topi = torch.max(decoder_output,2)\n",
    "            # if torch.sum(y_t[0,:,i])==0:\n",
    "            #     y_t = y_t.squeeze(0)\n",
    "            #     break\n",
    "            if torch.sum(topi)==0:\n",
    "                break\n",
    "            decoder_input_t = topi\n",
    "            decoder_input_t = decoder_input_t.view(batch_size_t)\n",
    "\n",
    "            # prediction\n",
    "            prediction[:,i] = decoder_input_t\n",
    "\n",
    "        for i in range(batch_size_t):\n",
    "            for j in range(maxlen):\n",
    "                if int(prediction[i][j]) ==0:\n",
    "                    break\n",
    "                else:\n",
    "                    prediction_sub.append(int(prediction[i][j]))\n",
    "            if len(prediction_sub)<maxlen:\n",
    "                prediction_sub.append(0)\n",
    "\n",
    "            for k in range(y_t.size()[1]):\n",
    "                if int(y_t[i][k]) ==0:\n",
    "                    break\n",
    "                else:\n",
    "                    label_sub.append(int(y_t[i][k]))\n",
    "            label_sub.append(0)\n",
    "\n",
    "            dist, llen = cmp_result(label_sub, prediction_sub)\n",
    "            total_dist += dist\n",
    "            total_label += llen\n",
    "            total_line += 1\n",
    "            if dist == 0:\n",
    "                total_line_rec = total_line_rec+ 1\n",
    "\n",
    "            label_sub = []\n",
    "            prediction_sub = []\n",
    "\n",
    "    print('total_line_rec is',total_line_rec)\n",
    "    wer = float(total_dist) / total_label\n",
    "    sacc = float(total_line_rec) / total_line\n",
    "    print('wer is %.5f' % (wer))\n",
    "    print('sacc is %.5f ' % (sacc))\n",
    "    # print('whole loss is %.5f'%(whole_loss_t/925))\n",
    "    # with open(\"training_data/wer_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
    "    #     f.write(\"%s\\n\" % (str(wer)))\n",
    "\n",
    "    if (sacc > exprate):\n",
    "        exprate = sacc\n",
    "        print(exprate)\n",
    "        print(\"saving the model....\")\n",
    "        print('encoder_lr%.5f_GN_te1_d05_SGD_bs6_mask_conv_bn_b_xavier.pkl' %(lr_rate))\n",
    "        torch.save(encoder.state_dict(), 'model/encoder_lr%.5f_GN_te1_d05_SGD_bs6_mask_conv_bn_b_xavier.pkl'%(lr_rate))\n",
    "        torch.save(attn_decoder1.state_dict(), 'model/attn_decoder_lr%.5f_GN_te1_d05_SGD_bs6_mask_conv_bn_b_xavier.pkl'%(lr_rate))\n",
    "        print(\"done\")\n",
    "        flag = 0\n",
    "    else:\n",
    "        flag = flag+1\n",
    "        print('the best is %f' % (exprate))\n",
    "        print('the loss is bigger than before,so do not save the model')\n",
    "\n",
    "    if flag == 10:\n",
    "        lr_rate = lr_rate*0.1\n",
    "        flag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1759, -0.1230]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmer",
   "language": "python",
   "name": "hmer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
